{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 193,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "import pandas as pd"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-17T21:29:26.578796200Z",
     "start_time": "2023-08-17T21:29:26.570429900Z"
    }
   },
   "id": "f1e79950949296a4"
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-08-17T21:29:26.579869500Z",
     "start_time": "2023-08-17T21:29:26.573625300Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(768, 9)\n",
      "<class 'list'>\n",
      "768\n"
     ]
    }
   ],
   "source": [
    "# Initialize the path and load data from the csv file\n",
    "path = 'pima-indians-diabetes.data.csv'\n",
    "data = np.genfromtxt(path, delimiter=',')\n",
    "\n",
    "# Print to check the data type and size\n",
    "print(type(data))\n",
    "print(data.shape)\n",
    "\n",
    "# Data converted from numpy.ndarray to list\n",
    "data = data.tolist()\n",
    "\n",
    "print(type(data))\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "outputs": [],
   "source": [
    "train = []\n",
    "val = []\n",
    "test = []\n",
    "\n",
    "\n",
    "def data_preparation(train_size, val_size, test_size):\n",
    "    random.shuffle(data)\n",
    "\n",
    "    for d in data:\n",
    "        num = random.random()\n",
    "        if 0 <= num <= train_size:\n",
    "            train.append(d)\n",
    "        elif train_size < num <= (train_size + val_size):\n",
    "            val.append(d)\n",
    "        else:\n",
    "            test.append(d)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-17T21:29:26.582823700Z",
     "start_time": "2023-08-17T21:29:26.578796200Z"
    }
   },
   "id": "2adbc3675339eeb9"
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "526\n",
      "123\n",
      "119\n"
     ]
    }
   ],
   "source": [
    "data_preparation(0.7, 0.15, 0.15)\n",
    "\n",
    "print(len(train))\n",
    "print(len(val))\n",
    "print(len(test))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-17T21:29:26.586554600Z",
     "start_time": "2023-08-17T21:29:26.585025Z"
    }
   },
   "id": "3fe757331d8ddd2b"
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-17T21:29:26.590124800Z",
     "start_time": "2023-08-17T21:29:26.588610700Z"
    }
   },
   "id": "d984049fd0ac4c89"
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "outputs": [],
   "source": [
    "# For each sample, X = [x1, x2, .... , xn] in the training set, we add a bias term x0 = 1\n",
    "# give the code for adding the bias term\n",
    "def add_bias_term(dataset):\n",
    "    for d in dataset:\n",
    "        d.insert(0, 1)\n",
    "\n",
    "# Randomly initialize theta = [theta0, theta1, .... , theta(n+1)] within 0 to 1\n",
    "def initialize_theta(n):\n",
    "    theta = []\n",
    "    for i in range(n + 1):\n",
    "        theta.append(random.random())\n",
    "    return theta\n",
    "\n",
    "# logistic regression training (update theta)\n",
    "history = []\n",
    "\n",
    "def logistic_regression(dataset, learning_rate, max_iterations):\n",
    "    dataset = add_bias_term(dataset)\n",
    "    theta = initialize_theta(len(dataset[0]) - 1)\n",
    "\n",
    "    for i in range(max_iterations):\n",
    "        total_cost = 0\n",
    "        for d in dataset:\n",
    "            z = np.dot(theta, d)\n",
    "            h = sigmoid(z)\n",
    "            cost = -d[-1] * math.log(h) - (1 - d[-1]) * math.log(1 - h)\n",
    "            total_cost += cost\n",
    "            dv = np.dot((h - d[-1]), d)\n",
    "            theta = theta - learning_rate * dv\n",
    "        total_cost = total_cost / len(dataset)\n",
    "\n",
    "        history.append(total_cost)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-17T21:29:26.605722600Z",
     "start_time": "2023-08-17T21:29:26.592214700Z"
    }
   },
   "id": "699f713a416e2d23"
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[199], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mlogistic_regression\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0.01\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m1000\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[198], line 19\u001B[0m, in \u001B[0;36mlogistic_regression\u001B[1;34m(dataset, learning_rate, max_iterations)\u001B[0m\n\u001B[0;32m     17\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mlogistic_regression\u001B[39m(dataset, learning_rate, max_iterations):\n\u001B[0;32m     18\u001B[0m     dataset \u001B[38;5;241m=\u001B[39m add_bias_term(dataset)\n\u001B[1;32m---> 19\u001B[0m     theta \u001B[38;5;241m=\u001B[39m initialize_theta(\u001B[38;5;28mlen\u001B[39m(\u001B[43mdataset\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m) \u001B[38;5;241m-\u001B[39m \u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m     21\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(max_iterations):\n\u001B[0;32m     22\u001B[0m         total_cost \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n",
      "\u001B[1;31mTypeError\u001B[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "logistic_regression(train, 0.01, 1000)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-17T21:29:26.613586100Z",
     "start_time": "2023-08-17T21:29:26.596670900Z"
    }
   },
   "id": "a91ba3c975fc199f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
